{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5b540b5e-bfdf-482e-9049-cdb1246c7801",
   "metadata": {},
   "source": [
    "# RAG Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e6bd00b-b919-4c21-a7b7-80600bed1a1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://download.pytorch.org/whl/mps\n",
      "Requirement already satisfied: torch in /opt/anaconda3/lib/python3.12/site-packages (2.8.0)\n",
      "\u001b[31mERROR: Could not find a version that satisfies the requirement torchvision (from versions: none)\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for torchvision\u001b[0m\u001b[31m\n",
      "\u001b[0mRequirement already satisfied: transformers in /opt/anaconda3/lib/python3.12/site-packages (4.56.2)\n",
      "Requirement already satisfied: sentence-transformers in /opt/anaconda3/lib/python3.12/site-packages (5.1.1)\n",
      "Requirement already satisfied: faiss-cpu in /opt/anaconda3/lib/python3.12/site-packages (1.12.0)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/lib/python3.12/site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /opt/anaconda3/lib/python3.12/site-packages (from transformers) (0.35.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/anaconda3/lib/python3.12/site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/anaconda3/lib/python3.12/site-packages (from transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/anaconda3/lib/python3.12/site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/anaconda3/lib/python3.12/site-packages (from transformers) (2023.10.3)\n",
      "Requirement already satisfied: requests in /opt/anaconda3/lib/python3.12/site-packages (from transformers) (2.32.2)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /opt/anaconda3/lib/python3.12/site-packages (from transformers) (0.22.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /opt/anaconda3/lib/python3.12/site-packages (from transformers) (0.6.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/anaconda3/lib/python3.12/site-packages (from transformers) (4.66.4)\n",
      "Requirement already satisfied: torch>=1.11.0 in /opt/anaconda3/lib/python3.12/site-packages (from sentence-transformers) (2.8.0)\n",
      "Requirement already satisfied: scikit-learn in /opt/anaconda3/lib/python3.12/site-packages (from sentence-transformers) (1.6.0)\n",
      "Requirement already satisfied: scipy in /opt/anaconda3/lib/python3.12/site-packages (from sentence-transformers) (1.13.1)\n",
      "Requirement already satisfied: Pillow in /opt/anaconda3/lib/python3.12/site-packages (from sentence-transformers) (10.3.0)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in /opt/anaconda3/lib/python3.12/site-packages (from sentence-transformers) (4.15.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/anaconda3/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2024.3.1)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /opt/anaconda3/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.1.10)\n",
      "Requirement already satisfied: setuptools in /opt/anaconda3/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (69.5.1)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /opt/anaconda3/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (1.14.0)\n",
      "Requirement already satisfied: networkx in /opt/anaconda3/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /opt/anaconda3/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (3.1.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.12/site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.12/site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.12/site-packages (from requests->transformers) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.12/site-packages (from requests->transformers) (2025.8.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /opt/anaconda3/lib/python3.12/site-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /opt/anaconda3/lib/python3.12/site-packages (from scikit-learn->sentence-transformers) (3.5.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/anaconda3/lib/python3.12/site-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/lib/python3.12/site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.3)\n",
      "Requirement already satisfied: PyPDF2 in /opt/anaconda3/lib/python3.12/site-packages (3.0.1)\n",
      "Requirement already satisfied: python-docx in /opt/anaconda3/lib/python3.12/site-packages (1.2.0)\n",
      "Requirement already satisfied: tqdm in /opt/anaconda3/lib/python3.12/site-packages (4.66.4)\n",
      "Requirement already satisfied: lxml>=3.1.0 in /opt/anaconda3/lib/python3.12/site-packages (from python-docx) (5.2.1)\n",
      "Requirement already satisfied: typing_extensions>=4.9.0 in /opt/anaconda3/lib/python3.12/site-packages (from python-docx) (4.15.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/mps\n",
    "!pip install transformers sentence-transformers faiss-cpu\n",
    "!pip install PyPDF2 python-docx tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a31390e-8a12-4f3e-b916-2d1ef90c5451",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4a17199b-09df-4ec6-961a-6ad16830a2cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: PyPDF2 in /opt/anaconda3/lib/python3.12/site-packages (3.0.1)\n",
      "Requirement already satisfied: python-docx in /opt/anaconda3/lib/python3.12/site-packages (1.2.0)\n",
      "Requirement already satisfied: tiktoken in /opt/anaconda3/lib/python3.12/site-packages (0.11.0)\n",
      "Requirement already satisfied: lxml>=3.1.0 in /opt/anaconda3/lib/python3.12/site-packages (from python-docx) (5.2.1)\n",
      "Requirement already satisfied: typing_extensions>=4.9.0 in /opt/anaconda3/lib/python3.12/site-packages (from python-docx) (4.15.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /opt/anaconda3/lib/python3.12/site-packages (from tiktoken) (2023.10.3)\n",
      "Requirement already satisfied: requests>=2.26.0 in /opt/anaconda3/lib/python3.12/site-packages (from tiktoken) (2.32.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.12/site-packages (from requests>=2.26.0->tiktoken) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.12/site-packages (from requests>=2.26.0->tiktoken) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.12/site-packages (from requests>=2.26.0->tiktoken) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.12/site-packages (from requests>=2.26.0->tiktoken) (2025.8.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install PyPDF2 python-docx tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "356cea64-7ff5-4c08-8941-66b2beb9a52f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: PyPDF2 in /opt/anaconda3/lib/python3.12/site-packages (3.0.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install PyPDF2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c6a15690-9460-48f1-85dd-96d87b405df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from PyPDF2 import PdfReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4a47053d-878b-47e1-bfde-3e6f8888a28f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the folder containing your PDF textbooks\n",
    "pdf_folder = Path(\"/Users/ayshairam/Desktop/Educational-Atlas-RAG/data/Educational textbooks/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "67523552-ab27-428e-bccf-ddf1161ec0f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_pdf(file_path):\n",
    "    text = \"\"\n",
    "    reader = PdfReader(file_path)\n",
    "    for page in reader.pages:\n",
    "        page_text = page.extract_text()\n",
    "        if page_text:\n",
    "            text += page_text + \"\\n\"\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "471338f7-de61-4b38-8460-c05493d1815e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading Principles-of-Data-Science-WEB.pdf...\n",
      "Reading Introduction_to_Python_Programming_-_WEB.pdf...\n",
      "Reading Introduction_To_Computer_Science_-_WEB.pdf...\n",
      "Reading Foundations_of_Information_Systems_-_WEB_oNlbGYl.pdf...\n",
      "\n",
      "Loaded 4 PDFs successfully!\n"
     ]
    }
   ],
   "source": [
    "all_texts = []\n",
    "\n",
    "for file in pdf_folder.iterdir():\n",
    "    if file.suffix.lower() == \".pdf\":   # only PDFs\n",
    "        print(f\"Reading {file.name}...\")\n",
    "        all_texts.append(read_pdf(file))\n",
    "\n",
    "print(f\"\\nLoaded {len(all_texts)} PDFs successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e32e7da8-8900-4d0f-9aef-b58dc90ae611",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total text chunks: 6036\n",
      "\t\n",
      "\t      Principles of Data Science          SENIOR CONTRIBUTING AUTHORS DR. SHAUN V. AULT, VALDOSTA STATE UNIVERSITY DR. SOOHYUN NAM LIAO, UNIVERSITY OF CALIFORNIA SAN DIEGO LARRY MUSOLINO, PENNSYLVANIA STATE UNIVERSITY         \n",
      "\n",
      "\t\n",
      "\tOpenStax Rice University 6100 Main Street MS-375 Houston, Texas 77005  To learn more about OpenStax, visit https://openstax.org. Individual print copies and bulk orders can be purchased through our website.  Â©2025 Rice University. Textbook content produced by OpenStax is licensed under a Creative Commons Attribution Non-Commercial ShareAlike 4.0 International License (CC BY-NC-SA 4.0). Under this license, any user of this textbook or the textbook contents herein can share, remix, and build upon the content for noncommercial purposes only. Any adaptations must be shared under the same type of license. In any case of sharing the original or adapted material, whether in whole or in part, the user must provide proper attribution as follows:  - If you noncommer\n"
     ]
    }
   ],
   "source": [
    "# Define chunk size (number of characters per chunk)\n",
    "chunk_size = 1000\n",
    "\n",
    "# Store all chunks here\n",
    "chunks = []\n",
    "\n",
    "# Loop through all loaded PDFs\n",
    "for pdf_text in all_texts:\n",
    "    # Join all pages if your PDF is split into pages\n",
    "    if isinstance(pdf_text, list):  # If you stored pages\n",
    "        pdf_text = \"\\n\".join([page.extract_text() for page in pdf_text if page.extract_text()])\n",
    "    \n",
    "    # Split into chunks\n",
    "    for i in range(0, len(pdf_text), chunk_size):\n",
    "        chunks.append(pdf_text[i:i+chunk_size])\n",
    "\n",
    "print(f\"Total text chunks: {len(chunks)}\")\n",
    "print(chunks[0])  # preview first chunk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1274d90c-0dac-4abd-a3a2-02911bbb50a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: PyPDF2 in /opt/anaconda3/envs/rag_env/lib/python3.12/site-packages (3.0.1)\n",
      "Requirement already satisfied: python-docx in /opt/anaconda3/envs/rag_env/lib/python3.12/site-packages (1.2.0)\n",
      "Requirement already satisfied: tiktoken in /opt/anaconda3/envs/rag_env/lib/python3.12/site-packages (0.11.0)\n",
      "Requirement already satisfied: openai in /opt/anaconda3/envs/rag_env/lib/python3.12/site-packages (1.109.1)\n",
      "Requirement already satisfied: faiss-cpu in /opt/anaconda3/envs/rag_env/lib/python3.12/site-packages (1.12.0)\n",
      "Requirement already satisfied: lxml>=3.1.0 in /opt/anaconda3/envs/rag_env/lib/python3.12/site-packages (from python-docx) (6.0.2)\n",
      "Requirement already satisfied: typing_extensions>=4.9.0 in /opt/anaconda3/envs/rag_env/lib/python3.12/site-packages (from python-docx) (4.15.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /opt/anaconda3/envs/rag_env/lib/python3.12/site-packages (from tiktoken) (2025.9.18)\n",
      "Requirement already satisfied: requests>=2.26.0 in /opt/anaconda3/envs/rag_env/lib/python3.12/site-packages (from tiktoken) (2.32.5)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /opt/anaconda3/envs/rag_env/lib/python3.12/site-packages (from openai) (4.11.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /opt/anaconda3/envs/rag_env/lib/python3.12/site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /opt/anaconda3/envs/rag_env/lib/python3.12/site-packages (from openai) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /opt/anaconda3/envs/rag_env/lib/python3.12/site-packages (from openai) (0.11.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /opt/anaconda3/envs/rag_env/lib/python3.12/site-packages (from openai) (2.11.9)\n",
      "Requirement already satisfied: sniffio in /opt/anaconda3/envs/rag_env/lib/python3.12/site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /opt/anaconda3/envs/rag_env/lib/python3.12/site-packages (from openai) (4.67.1)\n",
      "Requirement already satisfied: idna>=2.8 in /opt/anaconda3/envs/rag_env/lib/python3.12/site-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
      "Requirement already satisfied: certifi in /opt/anaconda3/envs/rag_env/lib/python3.12/site-packages (from httpx<1,>=0.23.0->openai) (2025.8.3)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/anaconda3/envs/rag_env/lib/python3.12/site-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /opt/anaconda3/envs/rag_env/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/anaconda3/envs/rag_env/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /opt/anaconda3/envs/rag_env/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->openai) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /opt/anaconda3/envs/rag_env/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->openai) (0.4.1)\n",
      "Requirement already satisfied: numpy<3.0,>=1.25.0 in /opt/anaconda3/envs/rag_env/lib/python3.12/site-packages (from faiss-cpu) (2.3.3)\n",
      "Requirement already satisfied: packaging in /opt/anaconda3/envs/rag_env/lib/python3.12/site-packages (from faiss-cpu) (25.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/anaconda3/envs/rag_env/lib/python3.12/site-packages (from requests>=2.26.0->tiktoken) (3.4.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/envs/rag_env/lib/python3.12/site-packages (from requests>=2.26.0->tiktoken) (2.5.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install PyPDF2 python-docx tiktoken openai faiss-cpu\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "77518e18-5035-4b95-8dc6-6bdc91778fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks = []  # list of all text chunks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "56156536-1948-4a67-b096-cd77d29bbfab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "# Initialize client\n",
    "client = OpenAI(api_key=\"My key\")\n",
    "\n",
    "# Updated function for embeddings\n",
    "def get_embedding(text, model=\"text-embedding-3-small\"):\n",
    "    response = client.embeddings.create(\n",
    "        model=model,\n",
    "        input=text\n",
    "    )\n",
    "    return response.data[0].embedding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "041b8a1e-4d53-46cc-b17a-7daf3f89aaa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings stored in FAISS index!\n"
     ]
    }
   ],
   "source": [
    "import faiss\n",
    "import numpy as np\n",
    "\n",
    "embedding_dim = 1536  # dimension of text-embedding-3-small\n",
    "index = faiss.IndexFlatL2(embedding_dim)  # L2 distance index\n",
    "\n",
    "# Store embeddings and associated text\n",
    "chunk_texts = []\n",
    "\n",
    "for chunk in chunks:\n",
    "    embedding = get_embedding(chunk)\n",
    "    index.add(np.array([embedding], dtype=np.float32))\n",
    "    chunk_texts.append(chunk)\n",
    "\n",
    "print(\"Embeddings stored in FAISS index!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c87c6f8d-8faf-46fe-afb7-3d71a6bca380",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scikit-learn is installed and working!\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "print(\"scikit-learn is installed and working!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "63c2c002-6bcf-4c9c-a81e-52817b13b4e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "571aa86e-75cf-453e-8b5d-52c7952aa61e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PDFs loaded: ['Principles-of-Data-Science-WEB.pdf', 'Introduction_to_Python_Programming_-_WEB.pdf', 'Introduction_To_Computer_Science_-_WEB.pdf', 'Foundations_of_Information_Systems_-_WEB_oNlbGYl.pdf']\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "pdf_folder = Path(\"/Users/ayshairam/Desktop/Educational-Atlas-RAG/data/Educational textbooks\")\n",
    "pdf_files = list(pdf_folder.glob(\"*.pdf\"))\n",
    "print(\"PDFs loaded:\", [f.name for f in pdf_files])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "94b83415-435f-44e3-8982-406ea1ca254f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentence-transformers in /opt/anaconda3/envs/rag_env/lib/python3.12/site-packages (5.1.1)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /opt/anaconda3/envs/rag_env/lib/python3.12/site-packages (from sentence-transformers) (4.56.2)\n",
      "Requirement already satisfied: tqdm in /opt/anaconda3/envs/rag_env/lib/python3.12/site-packages (from sentence-transformers) (4.67.1)\n",
      "Requirement already satisfied: torch>=1.11.0 in /opt/anaconda3/envs/rag_env/lib/python3.12/site-packages (from sentence-transformers) (2.8.0)\n",
      "Requirement already satisfied: scikit-learn in /opt/anaconda3/envs/rag_env/lib/python3.12/site-packages (from sentence-transformers) (1.7.2)\n",
      "Requirement already satisfied: scipy in /opt/anaconda3/envs/rag_env/lib/python3.12/site-packages (from sentence-transformers) (1.16.2)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in /opt/anaconda3/envs/rag_env/lib/python3.12/site-packages (from sentence-transformers) (0.35.1)\n",
      "Requirement already satisfied: Pillow in /opt/anaconda3/envs/rag_env/lib/python3.12/site-packages (from sentence-transformers) (11.3.0)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in /opt/anaconda3/envs/rag_env/lib/python3.12/site-packages (from sentence-transformers) (4.15.0)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/envs/rag_env/lib/python3.12/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (3.19.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/anaconda3/envs/rag_env/lib/python3.12/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2.3.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/anaconda3/envs/rag_env/lib/python3.12/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/anaconda3/envs/rag_env/lib/python3.12/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (6.0.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/anaconda3/envs/rag_env/lib/python3.12/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2025.9.18)\n",
      "Requirement already satisfied: requests in /opt/anaconda3/envs/rag_env/lib/python3.12/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2.32.5)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /opt/anaconda3/envs/rag_env/lib/python3.12/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.22.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /opt/anaconda3/envs/rag_env/lib/python3.12/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.6.2)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/anaconda3/envs/rag_env/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.9.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /opt/anaconda3/envs/rag_env/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (1.1.10)\n",
      "Requirement already satisfied: setuptools in /opt/anaconda3/envs/rag_env/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (78.1.1)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /opt/anaconda3/envs/rag_env/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (1.14.0)\n",
      "Requirement already satisfied: networkx in /opt/anaconda3/envs/rag_env/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (3.5)\n",
      "Requirement already satisfied: jinja2 in /opt/anaconda3/envs/rag_env/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/anaconda3/envs/rag_env/lib/python3.12/site-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/envs/rag_env/lib/python3.12/site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.3)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/anaconda3/envs/rag_env/lib/python3.12/site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/envs/rag_env/lib/python3.12/site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/envs/rag_env/lib/python3.12/site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/envs/rag_env/lib/python3.12/site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (2025.8.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /opt/anaconda3/envs/rag_env/lib/python3.12/site-packages (from scikit-learn->sentence-transformers) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /opt/anaconda3/envs/rag_env/lib/python3.12/site-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install sentence-transformers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8cd98e8a-48ea-402f-a3ab-18b5ad3753ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Load free embedding model (downloads only once)\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "def get_embedding(text):\n",
    "    return model.encode(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1734cedb-2d2f-4952-8841-89b41873184e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding length: 384\n"
     ]
    }
   ],
   "source": [
    "# Example\n",
    "embedding_vector = get_embedding(\"This is a test for embeddings.\")\n",
    "print(\"Embedding length:\", len(embedding_vector))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ec85e3df-7788-45bc-8aa4-ecd4b8174dfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 2329 chunks.\n",
      "FAISS index built with 2329 vectors.\n",
      "\n",
      "ðŸ”¹ Chunk 1:\n",
      "empo wers you to meticulously determine what those instructions should be. T ake, for instance, the str ategic gameplay involved in chess. T o excel in a chess match, a player must: â€¢Understand the unique mo vements and str ategic values of each piece, r ecognizing ho w each can be maneuver ed to contr ol the boar d. â€¢Visualize the boar dâ€™s layout, identifying potential thr eats and opportunities, and planning mo ves several steps ahead to secur e an advantageous position. â€¢Recognize patterns fr om pr evious games, understanding common tactics and counters, to formulate a robust, adaptable str ategy . In de vising a winning str ategy , computational thinking is the underpinning fr ame work: â€¢The comple x game is dissected into smaller , mor e manageable components (e.g., the function of each chess piece, the state of the boar d)â€”this is decomposition. â€¢Attention is concentr ated on pivotal elements that influence the game â€™s outcome, such as the positioning of ke y pieces and the opponent â€™s tendencies, sidelining less critical factorsâ€”this is an abstr action. â€¢Drawing fr om prior kno wledge and e xperiences in similar scenarios, a step-b y-step appr oach is developed to navigate thr ough the gameâ€”this is algorithmic thinking. Should you ventur e into de veloping your o wn chess pr ogram or str ategy , these ar e precisely the types of consider ations you would deliber ate on and r esolve befor e actual pr ogramming. Testing and Debugging Testing and debugging ar e techniques used to identify flaws in algorithms and defects in code to be able to correct them. T est cases r ely on pr oviding specific input data to check whether a softwar e program functions correctly and meets its designed r equir ements. T est cases need to be identified to drive tests. If a test associated with a test case fails, debugging needs to be conducted to identify the sour ce of the pr oblem and correct it. In other wor ds, debugging is about locating and fixing defects (i.e., bugs) in algorithms and processes to make them behave as e xpected. In pr ogramming, e veryone makes mistakes, the y are part of the learning pr ocess. The important thing is to identify the mistake and work out ho w to o vercome it. Ther e are those who feel that the deepest learning takes place when mistakes ar e made. In the jam sandwich algorithm, testing can be facilitated b y taking turns to play the r ole of the pr ogrammer who gives instructions as well as the r obot. If you ar e a pr ogrammer , your job is to r ead out the instructions and follo w each step. Y ou can choose to follo w your pseudocode or your flo wchart. Each instruction becomes a test case, and the test succeeds if the r obot can follo w every instruction e xactly and successfully .\n",
      "--------------------------------------------------\n",
      "\n",
      "ðŸ”¹ Chunk 2:\n",
      "eferenced in the chapter code may also be downloaded her e (https://openstax.or g/r/datach7) .7.5 â€¢ Natur al Language Pr ocessing 373Key Terms activation for a neur on, the pr ocess of sending an output signal after having r eceived appr opriate input signals activation function non-decr easing function fthat determines whether the neur on activates artificial intelligence (AI) branch of computer science that aims to cr eate intelligent systems capable of simulating humanlike cognitive abilities, including learning, r easoning, per ception, and decision-making backpr opagation an algorithm used to tr ain neur al networks b y determining ho w the err ors depend on changes in the weights and biases of all the neur ons, starting fr om the output layer and working backwar d through the layers, r ecursively updating the par ameters based on ho w the err or changes in each layer bias value bthat is added to the weighted signal, making the neur on mor e likely (or less likely , ifbis negative) to activate on any given input binary cr oss entr opy loss loss function commonly used in binary classification tasks: ChatGPT Powerful natur al language pr ocessing platform, cr eated b y OpenAI connecting weight in a r ecurr ent neur al network, a weight that e xists on a connection fr om one neur on to itself or to a cycle of neur ons in a feedback loop convolutional layers layers of a CNN that applies convolution filters to the input data to pr oduce a featur e map convolutional neur al network (CNN) class of neur al network models de veloped to pr ocess structur ed, grid- like data, such as images, making use of the mathematical oper ation of convolution deep learning training and implementation of neur al networks with many layers to learn hier archical (structur ed) r epresentations of data deepfake product of an AI system that seem r ealistic, cr eated with malicious intent to mislead people depth number of hidden layers in a neur al network dimension the number of components in a vector dynamic backpr opagation adjustment of par ameters (weights and biases) and the underlying structur e (neur ons, layers, connections, etc.) in the tr aining of a neur al network epoch single r ound of tr aining of a neur al network using the entir e training set (or a batch ther eof) exploding gr adient pr oblem failur e to tr ain an RNN due to instability intr oduced b y having connecting weights at values lar ger than 1 featur e map output of convolutional layers in a CNN, r epresenting the learned featur es of the input data feedback loop internal connection fr om one neur on to itself or among multiple neur ons in a cycle fully connected layers layers of a neur al network in which e very neur on in one layer is connected to e very neur on in the ne xt layer gener ative art\n",
      "--------------------------------------------------\n",
      "\n",
      "ðŸ”¹ Chunk 3:\n",
      "an initial step to find patterns in the dataset, allo wing the data to be labeled in some way . Then supervised learning techniques may be applied to the labeled data as a tr aining step. The model cr eated in this way may then be used to determine the best labels for futur e (unlabeled) data. Supervised Learning Supervised learning is analogous to a student learning fr om an instructor . At first, the student may answer many questions incorr ectly , but the instructor is ther e to corr ect the student each time. When the student gives (mostly) corr ect r esponses, ther e is e vidence that the student has sufficiently learned the material and would be able to answer similar questions corr ectly out in the r eal world wher e it r eally matters. The goal of supervised learning is to pr oduce a model that gives a mapping fr om the set of inputs or featur es to a set of output values or labels (see Figur e 6.2 ). The model is function , wher e is the input arr ay and is the output value or label. The way that it does this is thr ough tr aining and testing. When tr aining, the algorithm cr eates a corr espondence between input featur es and the output value or label, often going through many iter ations of trial and err or until a desir ed le vel of accur acy is achie ved. The model is then tested on additional data, and if the accur acy r emains high enough, then the model may be deplo yed for use in r eal- world applications. Otherwise, the model may need to be adjusted substantially or abandoned altogether . Figur e6.2The Supervised Learning Cycle. The supervised learning cycle consists of gathering data, tr aining on some part of the data, testing on another part of the data, and deplo yment to solve pr oblems about ne w data. Examples of supervised learning models include linear r egression (discussed in Corr elation and Linear Regr ession Analysis ), logistic r egression, naÃ¯ve Bayes classification, decision tr ees, r andom for ests, and many6.1 â€¢ What Is Machine Learning? 271kinds of neur al networks. Linear r egression may not seem like a machine learning algorithm because ther e are nocorrection steps. A formula simply pr oduces the line of best fit. Ho wever, the r egression formula itself represents an optimization that r educes the err or in the values pr edicted b y the r egression line versus the actual data. If the linear r egression model is not accur ate enough, additional data could be collected to impr ove the accur acy of the model, and once the r egression line is found, it may then be used to pr edict values that wer e not in the initial dataset. Linear r egression has been de veloped in pr evious chapters, and you\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import faiss\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from PyPDF2 import PdfReader\n",
    "\n",
    "# -----------------------------\n",
    "# 1. Load Hugging Face embedding model (FREE)\n",
    "# -----------------------------\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")  # 384-dim embeddings\n",
    "\n",
    "def get_embedding(text):\n",
    "    return model.encode(text)\n",
    "\n",
    "# -----------------------------\n",
    "# 2. Load and chunk PDFs\n",
    "# -----------------------------\n",
    "def load_pdfs(pdf_folder):\n",
    "    all_texts = []\n",
    "    for file in os.listdir(pdf_folder):\n",
    "        if file.endswith(\".pdf\"):\n",
    "            pdf_path = os.path.join(pdf_folder, file)\n",
    "            reader = PdfReader(pdf_path)\n",
    "            text = \"\"\n",
    "            for page in reader.pages:\n",
    "                text += page.extract_text() or \"\"\n",
    "            all_texts.append(text)\n",
    "    return all_texts\n",
    "\n",
    "def chunk_text(text, chunk_size=500, overlap=50):\n",
    "    words = text.split()\n",
    "    chunks = []\n",
    "    for i in range(0, len(words), chunk_size - overlap):\n",
    "        chunk = \" \".join(words[i:i+chunk_size])\n",
    "        chunks.append(chunk)\n",
    "    return chunks\n",
    "\n",
    "pdf_folder = \"/Users/ayshairam/Desktop/Educational-Atlas-RAG/data/Educational textbooks\"\n",
    "documents = load_pdfs(pdf_folder)\n",
    "\n",
    "chunk_texts = []\n",
    "for doc in documents:\n",
    "    chunk_texts.extend(chunk_text(doc))\n",
    "\n",
    "print(f\"Loaded {len(chunk_texts)} chunks.\")\n",
    "\n",
    "# -----------------------------\n",
    "# 3. Build FAISS index\n",
    "# -----------------------------\n",
    "embeddings = np.array([get_embedding(chunk) for chunk in chunk_texts], dtype=\"float32\")\n",
    "\n",
    "dimension = embeddings.shape[1]  # 384\n",
    "index = faiss.IndexFlatL2(dimension)\n",
    "index.add(embeddings)\n",
    "\n",
    "print(f\"FAISS index built with {index.ntotal} vectors.\")\n",
    "\n",
    "# -----------------------------\n",
    "# 4. Retrieval function\n",
    "# -----------------------------\n",
    "def retrieve(query, k=3):\n",
    "    query_vector = np.array([get_embedding(query)], dtype=\"float32\")\n",
    "    distances, indices = index.search(query_vector, k)\n",
    "    results = [chunk_texts[i] for i in indices[0]]\n",
    "    return results\n",
    "\n",
    "# -----------------------------\n",
    "# 5. Test query\n",
    "# -----------------------------\n",
    "query = \"Explain reinforcement learning.\"\n",
    "top_chunks = retrieve(query, k=3)\n",
    "\n",
    "for i, c in enumerate(top_chunks):\n",
    "    print(f\"\\nðŸ”¹ Chunk {i+1}:\\n{c}\\n{'-'*50}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a554ba58-3567-412b-9841-9110debcdde9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import json\n",
    "\n",
    "def chat_ollama(query, model=\"llama3\"):\n",
    "    # Run Ollama CLI with the query\n",
    "    result = subprocess.run(\n",
    "        [\"ollama\", \"chat\", model, \"-m\", json.dumps([{\"role\":\"user\",\"content\": query}])],\n",
    "        capture_output=True,\n",
    "        text=True\n",
    "    )\n",
    "    return result.stdout\n",
    "\n",
    "answer = chat_ollama(\"Explain reinforcement learning\")\n",
    "print(answer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ff51ea9-3e9f-4cf1-ac05-32efb358a5a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import json\n",
    "\n",
    "def chat_ollama(query, model=\"llama3\"):\n",
    "    # Run Ollama CLI with the query\n",
    "    result = subprocess.run(\n",
    "        [\"ollama\", \"chat\", model, \"-m\", json.dumps([{\"role\":\"user\",\"content\": query}])],\n",
    "        capture_output=True,\n",
    "        text=True\n",
    "    )\n",
    "    return result.stdout\n",
    "\n",
    "answer = chat_ollama(\"Explain reinforcement learning\")\n",
    "print(answer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "980ed725-eb87-4807-8142-72df52a13f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_text(text, chunk_size=500):\n",
    "    words = text.split()\n",
    "    chunks = []\n",
    "    for i in range(0, len(words), chunk_size):\n",
    "        chunks.append(\" \".join(words[i:i+chunk_size]))\n",
    "    return chunks\n",
    "\n",
    "chunked_texts = []\n",
    "for t in all_texts:\n",
    "    chunked_texts.extend(chunk_text(t))\n",
    "\n",
    "print(f\"Total chunks: {len(chunked_texts)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79f5b49d-2314-486a-abd8-4150a7ceec7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import json\n",
    "\n",
    "def query_llama3(prompt):\n",
    "    # Run Ollama in subprocess\n",
    "    result = subprocess.run(\n",
    "        [\"ollama\", \"run\", \"llama3\", \"--\", prompt],\n",
    "        capture_output=True,\n",
    "        text=True\n",
    "    )\n",
    "    return result.stdout\n",
    "\n",
    "# Example query\n",
    "response = query_llama3(\"Explain what RAG means in simple terms.\")\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c99b91d-883c-43cc-809a-1ae17aef9d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Step 4a: Convert chunks to vectors\n",
    "vectorizer = TfidfVectorizer()\n",
    "chunk_vectors = vectorizer.fit_transform(chunked_texts)\n",
    "\n",
    "# Step 4b: Function to retrieve top-k chunks\n",
    "def retrieve_top_chunks(query, top_k=3):\n",
    "    query_vec = vectorizer.transform([query])\n",
    "    similarities = cosine_similarity(query_vec, chunk_vectors)\n",
    "    top_indices = similarities.argsort()[0][-top_k:][::-1]\n",
    "    return [chunked_texts[i] for i in top_indices]\n",
    "\n",
    "# Step 4c: Ask a query\n",
    "query = \"Explain reinforcement learning\"\n",
    "top_chunks = retrieve_top_chunks(query)\n",
    "context = \"\\n\".join(top_chunks)\n",
    "\n",
    "# Step 4d: Send context to Llama3\n",
    "response = query_llama3(f\"Using the following context, explain: {query}\\n\\nContext:\\n{context}\")\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0220281-3629-4618-b78d-22c4cb5577c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core libraries\n",
    "import os\n",
    "from pathlib import Path\n",
    "import subprocess\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from PyPDF2 import PdfReader\n",
    "\n",
    "print(\"All libraries imported successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ac64042-232c-4165-a975-d6997ee86a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import json\n",
    "\n",
    "def query_llama3(prompt):\n",
    "    # Run Ollama in subprocess\n",
    "    result = subprocess.run(\n",
    "        [\"ollama\", \"run\", \"llama3\", \"--\", prompt],\n",
    "        capture_output=True,\n",
    "        text=True\n",
    "    )\n",
    "    return result.stdout\n",
    "\n",
    "# Example query\n",
    "response = query_llama3(\"Explain what RAG means in simple terms.\")\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2725c548-d7cd-4562-9561-7ed526986935",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Step 4a: Convert chunks to vectors\n",
    "vectorizer = TfidfVectorizer()\n",
    "chunk_vectors = vectorizer.fit_transform(chunked_texts)\n",
    "\n",
    "# Step 4b: Function to retrieve top-k chunks\n",
    "def retrieve_top_chunks(query, top_k=3):\n",
    "    query_vec = vectorizer.transform([query])\n",
    "    similarities = cosine_similarity(query_vec, chunk_vectors)\n",
    "    top_indices = similarities.argsort()[0][-top_k:][::-1]\n",
    "    return [chunked_texts[i] for i in top_indices]\n",
    "\n",
    "# Step 4c: Ask a query\n",
    "query = \"Explain reinforcement learning\"\n",
    "top_chunks = retrieve_top_chunks(query)\n",
    "context = \"\\n\".join(top_chunks)\n",
    "\n",
    "# Step 4d: Send context to Llama3\n",
    "response = query_llama3(f\"Using the following context, explain: {query}\\n\\nContext:\\n{context}\")\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7bac3e6e-da05-45b1-af9d-a186bc640f45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Core RAG functions defined.\n"
     ]
    }
   ],
   "source": [
    "# =========================================================\n",
    "# CELL 1: Imports, Setup, and Core Functions\n",
    "# =========================================================\n",
    "import os\n",
    "import subprocess\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "# Imports for PDF reading, Indexing, and Retrieval:\n",
    "from PyPDF2 import PdfReader\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "# Imports for the Interactive Widget:\n",
    "from IPython.display import display\n",
    "import ipywidgets as widgets\n",
    "import sys\n",
    "import traceback\n",
    "\n",
    "# --- 1. Ollama/Llama3 Function ---\n",
    "def query_llama3(prompt):\n",
    "    \"\"\"\n",
    "    Sends a query to your local Llama3 model via Ollama CLI.\n",
    "    \"\"\"\n",
    "    result = subprocess.run(\n",
    "        [\"ollama\", \"run\", \"llama3\", \"--\", prompt],\n",
    "        capture_output=True,\n",
    "        text=True\n",
    "    )\n",
    "    if result.returncode != 0:\n",
    "        return f\"OLLAMA ERROR: Could not run Llama3. Is Ollama running and is 'llama3' pulled? Error: {result.stderr}\"\n",
    "    return result.stdout\n",
    "\n",
    "# --- 2. PDF Loading Function ---\n",
    "def load_pdfs(pdf_folder):\n",
    "    all_texts = []\n",
    "    if not pdf_folder.exists():\n",
    "         print(f\"Error: Folder not found at {pdf_folder}\")\n",
    "         return all_texts\n",
    "\n",
    "    for file in pdf_folder.iterdir():\n",
    "        if file.suffix.lower() == \".pdf\":\n",
    "            try:\n",
    "                reader = PdfReader(file)\n",
    "                text = \"\"\n",
    "                for page in reader.pages:\n",
    "                    page_text = page.extract_text()\n",
    "                    if page_text:\n",
    "                        text += page_text\n",
    "                all_texts.append(text)\n",
    "            except Exception as e:\n",
    "                print(f\"Error reading {file.name}: {e}\")\n",
    "    return all_texts\n",
    "\n",
    "# --- 3. Text Chunking Function ---\n",
    "def chunk_text(text, chunk_size=500):\n",
    "    words = text.split()\n",
    "    chunks = []\n",
    "    for i in range(0, len(words), chunk_size):\n",
    "        chunks.append(\" \".join(words[i:i+chunk_size]))\n",
    "    return chunks\n",
    "\n",
    "print(\"Core RAG functions defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "99faa2c4-1232-41e5-87e5-1dc0c6be1d3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 4 PDF files.\n",
      "Total chunks created: 2096\n",
      "TF-IDF vector index created successfully.\n"
     ]
    }
   ],
   "source": [
    "# =========================================================\n",
    "# CELL 2: Load Data and Build Index (Creates vectorizer/chunk_vectors)\n",
    "# =========================================================\n",
    "# !!! VERIFY THIS PATH IS CORRECT !!!\n",
    "pdf_folder = Path(\"/Users/ayshairam/Desktop/Educational-Atlas-RAG/data/Educational textbooks\") \n",
    "\n",
    "# Load texts\n",
    "all_texts = load_pdfs(pdf_folder)\n",
    "print(f\"Loaded {len(all_texts)} PDF files.\")\n",
    "\n",
    "# Create chunks\n",
    "chunked_texts = []\n",
    "for t in all_texts:\n",
    "    chunked_texts.extend(chunk_text(t))\n",
    "\n",
    "print(f\"Total chunks created: {len(chunked_texts)}\")\n",
    "\n",
    "# Build TF-IDF vectorizer (This creates the global variable 'vectorizer')\n",
    "if not chunked_texts:\n",
    "    raise ValueError(\"No text chunks were created. Cannot build index.\")\n",
    "    \n",
    "vectorizer = TfidfVectorizer()\n",
    "chunk_vectors = vectorizer.fit_transform(chunked_texts)\n",
    "\n",
    "print(\"TF-IDF vector index created successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "bc45f667-287a-4b27-83ac-97615d046b0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieval function 'retrieve_top_chunks' is ready.\n"
     ]
    }
   ],
   "source": [
    "# =========================================================\n",
    "# CELL 3: Define Retrieval Function (Uses vectorizer/chunk_vectors)\n",
    "# =========================================================\n",
    "def retrieve_top_chunks(query, top_k=3):\n",
    "    \"\"\"\n",
    "    Finds the top_k most similar chunks to the query using the TF-IDF index.\n",
    "    \"\"\"\n",
    "    # These two lines failed before because Cell 2 wasn't properly run.\n",
    "    query_vec = vectorizer.transform([query])\n",
    "    similarities = cosine_similarity(query_vec, chunk_vectors)\n",
    "    \n",
    "    top_indices = similarities.argsort()[0][-top_k:][::-1]\n",
    "    return [chunked_texts[i] for i in top_indices]\n",
    "\n",
    "print(\"Retrieval function 'retrieve_top_chunks' is ready.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "7fcca5b5-8bba-4e9a-9d28-d244228dcf01",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "python(24804) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Query: What are the core principles of data science?\n",
      "========== RAG Output ==========\n",
      "Based on the provided context, the core principles of data science are not explicitly stated. However, we can infer some key principles from the text:\n",
      "\n",
      "1. **Multidisciplinary approach**: Data science is an interdisciplinary field that combines collecting, processing, and analyzing large volumes of data to extract insights and drive informed decision-making.\n",
      "2. **Iterative process**: The data science life cycle is an iterative process that starts with data acquisition, followed by data exploration, data analysis, and reporting/presentation.\n",
      "3. **Data-driven insights**: Data science aims to derive insights from data, which can be used to make informed decisions in various fields such as healthcare, business, education, politics, environmental science, and social sciences.\n",
      "4. **Tools and software**: Data science involves the use of specialized tools and software, such as NumPy and Pandas, for data manipulation and analysis.\n",
      "5. **Exploratory data analysis**: Data scientists conduct exploratory data analysis to understand the characteristics of the data, identify patterns, and prepare it for further analysis.\n",
      "6. **Data visualization**: Data visualization is used to communicate insights and findings to stakeholders through reports and presentations.\n",
      "\n",
      "These principles are implicit in the text, but a more explicit discussion of the core principles of data science would typically include:\n",
      "\n",
      "1. **Data quality**: The importance of ensuring the accuracy, completeness, and integrity of the data.\n",
      "2. **Domain knowledge**: The need for domain-specific knowledge and understanding to effectively apply data science techniques.\n",
      "3. **Interpretability**: The importance of being able to interpret and communicate the results of data analysis to stakeholders.\n",
      "4. **Scalability**: The need to develop scalable solutions that can handle large datasets and complex analyses.\n",
      "\n",
      "These principles are not explicitly stated in the provided context, but they are important considerations in the field of data science.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# =========================================================\n",
    "# CELL 4: RAG Test\n",
    "# =========================================================\n",
    "test_query = \"What are the core principles of data science?\"\n",
    "\n",
    "try:\n",
    "    # 1. Retrieve top relevant chunks from PDFs\n",
    "    top_chunks = retrieve_top_chunks(test_query, top_k=3)\n",
    "    context = \"\\n\".join(top_chunks)\n",
    "\n",
    "    # 2. Generate response using Llama3\n",
    "    prompt = f\"Using the following context, explain: {test_query}\\n\\nContext:\\n{context}\"\n",
    "    response = query_llama3(prompt)\n",
    "\n",
    "    print(f\"Test Query: {test_query}\")\n",
    "    print(\"========== RAG Output ==========\")\n",
    "    print(response)\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"ERROR: RAG Test Failed. Details: {e}\")\n",
    "    print(\"Ensure Ollama is running and all preceding cells were executed in order.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "cefd8e22-9bd1-4b63-9a22-982045d9b957",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gt/jf5bv_6x3yz87k55wq389yk40000gn/T/ipykernel_24127/1307641401.py:55: DeprecationWarning: on_submit is deprecated. Instead, set the .continuous_update attribute to False and observe the value changing with: mywidget.observe(callback, 'value').\n",
      "  query_input.on_submit(handle_query)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9eb08faaefb74a3ca560a9548fc15c2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='', description='Query:', layout=Layout(width='70%'), placeholder='Type your question here...')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d0219b409224e549d6c2daea27261d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# =========================================================\n",
    "# CELL 5: Interactive Query Widget (Step 7) - FIXED\n",
    "# =========================================================\n",
    "# --- ADD NECESSARY IMPORTS HERE ---\n",
    "from IPython.display import display\n",
    "import ipywidgets as widgets\n",
    "import sys\n",
    "import traceback\n",
    "# ----------------------------------\n",
    "\n",
    "# Create a text input box\n",
    "query_input = widgets.Text(\n",
    "    value='',\n",
    "    placeholder='Type your question here...',\n",
    "    description='Query:',\n",
    "    layout=widgets.Layout(width='70%')\n",
    ")\n",
    "\n",
    "# Create an output area\n",
    "output_area = widgets.Output()\n",
    "\n",
    "# Define what happens when you submit a query\n",
    "def handle_query(sender):\n",
    "    output_area.clear_output()\n",
    "    user_query = query_input.value\n",
    "    if not user_query.strip():\n",
    "        return\n",
    "    \n",
    "    with output_area:\n",
    "        print(f\"User Query: {user_query}\")\n",
    "        \n",
    "        try:\n",
    "            # 1. Retrieve top chunks\n",
    "            print(\"-> Retrieving relevant context...\")\n",
    "            # These functions rely on Cell 3 & 1\n",
    "            top_chunks = retrieve_top_chunks(user_query, top_k=3)\n",
    "            context = \"\\n\".join(top_chunks)\n",
    "            \n",
    "            # 2. Query Llama3\n",
    "            print(\"-> Generating response with Llama3...\")\n",
    "            prompt = f\"Using the following context, explain: {user_query}\\n\\nContext:\\n{context}\"\n",
    "            response = query_llama3(prompt)\n",
    "            \n",
    "            # 3. Display response\n",
    "            print(\"\\n========== RAG Output ==========\")\n",
    "            print(response)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"RAG Chain Error: {e}\")\n",
    "            print(\"\\n--- Full Traceback ---\")\n",
    "            traceback.print_exc(file=sys.stdout)\n",
    "\n",
    "\n",
    "# Trigger on Enter key press\n",
    "query_input.on_submit(handle_query)\n",
    "\n",
    "# Display input and output in notebook\n",
    "display(query_input, output_area)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9f7a916-204e-4004-9861-e05dc7b4f7d2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (rag_env)",
   "language": "python",
   "name": "rag_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
